# Kalp-Hastaligi-Tahmini
Python ve Scikit-learn ile Makine Ã–ÄŸrenimi projesi: Kalp hastalÄ±ÄŸÄ± tahmini
# Makine Ã–ÄŸrenimi Projesi: Kalp HastalÄ±ÄŸÄ± Tahmini

**AmaÃ§:** Bu proje, bir hastanÄ±n tÄ±bbi verilerine (yaÅŸ, kolesterol, kan basÄ±ncÄ± vb.) dayanarak, o kiÅŸinin kalp hastasÄ± olup olmadÄ±ÄŸÄ±nÄ± (%88'in Ã¼zerinde bir doÄŸrulukla) tahmin eden bir Makine Ã–ÄŸrenimi (SÄ±nÄ±flandÄ±rma) modeli geliÅŸtirmeyi amaÃ§lamaktadÄ±r.

**PortfÃ¶ydeki Etkisi:** Bu proje, baÅŸtan sona bir veri bilimi yaÅŸam dÃ¶ngÃ¼sÃ¼nÃ¼ uygulama becerimi gÃ¶stermektedir:
* Ham ve kirli veriyi analiz etme ve temizleme.
* Modelin anlayacaÄŸÄ± formata getirmek iÃ§in **Ã–n Ä°ÅŸleme (Preprocessing)** ve **Ã–zellik MÃ¼hendisliÄŸi (Feature Engineering)** yapma.
* **Scikit-learn (sklearn)** kÃ¼tÃ¼phanesi ile model eÄŸitme ve deÄŸerlendirme.
* Modeli **iyileÅŸtirme (Optimization)** (Ã¶rn: Feature Scaling) ve farklÄ± modelleri (Lojistik Regresyon vs. Random Forest) karÅŸÄ±laÅŸtÄ±rma.

**KullanÄ±lan AraÃ§lar:**
* Python
* Pandas (Veri temizleme, filtreleme ve Ã¶n iÅŸleme iÃ§in)
* Scikit-learn (StandardScaler, LogisticRegression, RandomForestClassifier, train_test_split, accuracy_score)
* Matplotlib & Seaborn (Ä°lk analizler iÃ§in)
* Google Colab (Analiz ortamÄ±)

---

## ğŸ§­ Analiz ve Modelleme Ä°ÅŸ AkÄ±ÅŸÄ± (Workflow)

Proje, "ham" veriden "tahmin" modeline giden 4 ana adÄ±mda tamamlanmÄ±ÅŸtÄ±r:

### 1. Veri KeÅŸfi ve Temizleme

* **Ä°lk Analiz:** YÃ¼klenen ham veri seti (920 hasta), aslÄ±nda 4 farklÄ± tÄ±bbi merkezden (Cleveland, Hungary, vb.) toplanan verilerin birleÅŸtirilmiÅŸ haliydi.
* **Kritik Tespit:** DiÄŸer 3 merkezdeki verilerde `ca`, `slope` ve `thal` gibi kritik sÃ¼tunlarda %50'nin Ã¼zerinde eksik veri olduÄŸu tespit edildi.
* **Profesyonel Karar:** Modeli yanÄ±ltÄ±cÄ± verilerle eÄŸitmek yerine, bu 4 set iÃ§indeki **en eksiksiz ve en gÃ¼venilir** alt kÃ¼me olan **"Cleveland"** veri seti (304 hasta) ile Ã§alÄ±ÅŸmaya karar verildi.

### 2. Veri Ã–n Ä°ÅŸleme (Preprocessing)

Modelimizi eÄŸitebilmek iÃ§in "Cleveland" alt seti Ã¼zerinde iki temel dÃ¶nÃ¼ÅŸÃ¼m yapÄ±ldÄ±:

1.  **Eksik Veri YÃ¶netimi:** Yeni setteki az sayÄ±daki (%3'ten az) eksik veri iÃ§eren satÄ±rlar, veri bÃ¼tÃ¼nlÃ¼ÄŸÃ¼nÃ¼ bozmadÄ±ÄŸÄ± iÃ§in `dropna()` ile temizlendi (Son veri boyutu: 297 hasta).
2.  **Ã–zellik MÃ¼hendisliÄŸi (Feature Engineering):**
    * **Hedef DeÄŸiÅŸken (`target`):** Orijinal `num` (0-4 arasÄ±) sÃ¼tunu, modelimizin amacÄ± olan "ikili sÄ±nÄ±flandÄ±rma" (binary classification) iÃ§in `0` (SaÄŸlÄ±klÄ±) ve `1` (Hasta) olacak ÅŸekilde yeniden kodlandÄ±.
    * **Kategorik Veri:** Modelin anlayabilmesi iÃ§in `sex` (Male/Female), `cp` (angina types) gibi tÃ¼m `object` (metin) tipindeki sÃ¼tunlar, `pd.get_dummies()` (One-Hot Encoding) yÃ¶ntemiyle sayÄ±sal formata (0/1) dÃ¶nÃ¼ÅŸtÃ¼rÃ¼ldÃ¼.

### 3. Baseline Model (Temel Model)

* Veri seti %80 EÄŸitim (Train) ve %20 Test olarak ayrÄ±ldÄ±.
* Ä°lk temel model olarak `LogisticRegression` kullanÄ±ldÄ±.
* **Ä°lk SonuÃ§ (Baseline): %86.67 DoÄŸruluk (Accuracy)**
* **Tespit Edilen Sorun:** Model eÄŸitilirken, `age` (30-70), `chol` (120-500) ve `sex` (0-1) gibi sÃ¼tunlar arasÄ±ndaki devasa Ã¶lÃ§ek farklarÄ± nedeniyle bir `ConvergenceWarning` (YakÄ±nsama UyarÄ±sÄ±) alÄ±ndÄ±.

### 4. Model Ä°yileÅŸtirme ve DeÄŸerlendirme

Modeli hem profesyonel standartlara getirmek (uyarÄ±yÄ± gidermek) hem de baÅŸarÄ±sÄ±nÄ± artÄ±rmak iÃ§in **Ã–zellik Ã–lÃ§eklendirme (Feature Scaling)** uygulandÄ±:

1.  **Ã–lÃ§eklendirme:** `StandardScaler` kullanÄ±larak tÃ¼m `X_train` ve `X_test` verilerinin Ã¶lÃ§eÄŸi (ortalama 0, std 1) eÅŸitlendi.
2.  **Modelin Yeniden EÄŸitilmesi:** Ã–lÃ§eklenmiÅŸ veri ile `LogisticRegression` modeli *tekrar* eÄŸitildi.

---

## ğŸ“Š SonuÃ§lar ve KarÅŸÄ±laÅŸtÄ±rma

#### KazanÃ§ 1: Teknik BaÅŸarÄ±
`StandardScaler` kullanÄ±ldÄ±ktan sonra `ConvergenceWarning` uyarÄ±sÄ± **baÅŸarÄ±yla giderildi**. Bu, modelin artÄ±k matematiksel olarak daha stabil ve gÃ¼venilir bir Ã§Ã¶zÃ¼m bulduÄŸunu kanÄ±tladÄ±.

#### KazanÃ§ 2: Model BaÅŸarÄ±sÄ±
Ã–lÃ§eklendirme, modelin baÅŸarÄ±sÄ±nÄ± doÄŸrudan artÄ±rdÄ± ve **Ã¶zellikle "Hasta" (`1`) sÄ±nÄ±fÄ±nÄ± yakalama baÅŸarÄ±sÄ±nÄ± (`f1-score`) yÃ¼kseltti.**

| Model | DoÄŸruluk (Accuracy) | 'Hasta' SÄ±nÄ±fÄ± f1-score |
| :--- | :---: | :---: |
| Baseline (Ã–lÃ§eklenmemiÅŸ LR) | 86.67% | 0.83 |
| **Ä°yileÅŸtirilmiÅŸ (Ã–lÃ§eklenmiÅŸ LR)** | **88.33%** | **0.86** |

#### Deney 3: Model KarÅŸÄ±laÅŸtÄ±rmasÄ±
Daha karmaÅŸÄ±k bir model olan `RandomForestClassifier` da denendi. Bu model de **%88.33** doÄŸruluk skoru verdi.

**Proje Sonucu (Insight):** Her iki modelin de aynÄ± sonucu vermesi, verimizdeki "hasta" ve "saÄŸlÄ±klÄ±" ayrÄ±mÄ±nÄ±n `LogisticRegression` gibi daha basit (lineer) bir modelle bile etkili bir ÅŸekilde yakalanabildiÄŸini gÃ¶stermektedir. Bu durumda, daha hÄ±zlÄ± ve yorumlanmasÄ± daha kolay olan **Lojistik Regresyon modeli** tercih edilen modeldir.
